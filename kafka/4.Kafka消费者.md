- #### KafkaConsumer概念
```
1.Kafka消费者从属于消费者群组，一个群组里的消费者订阅的是同一个主题，每个消费者接收主题一部分分区的消息
2.如果消费者群组里的消费者超过主题的分区数量，有一部分消费者就会闲置，不会收到任何消息
3.往群组里增加消费者是横向伸缩消费者的主要方式，每个消费者只处理部分分区的消息，
  可以为主题创建大量的分区，在负载增长时可以加入更多的消费者
4.在多个应用程序从同一个主题读取数据的情况下，如果每个应用程序都要获取所有的消息，而不只是其中的一部分，
  只要保证每个应用程序有自己的消费者群组，就可以获取到主题的所有消息
5.在主题发生变化时，比如管理员添加了新的分区，会发生分区重分配，分区的所有权从一个消费者转移到另一个消费者，被称为再均衡
6.在再均衡期间，消费者无法读取消息，造成整个群组一小段时间的不可用，当分区被重新分配给另一个消费者时，
  消费者当前的读取状态会丢失，可能还需要刷新缓存，在重新恢复之前可能会拖慢应用程序
7.消费者通过向被指派为群组协调器的broker发送心跳来维持它们和群组的从属关系以及对分区的所有权
8.消费者会在轮询消息或提交偏移量时发送心跳，如果消费者停止发送心跳的时间足够长，会话就会过期，群组协调器认为消费者已经死亡，就会触发一次再均衡
```

- #### 分配分区过程
```
1.当消费者要加入群组时，会向群组协调器发送一个JoinGroup请求，第一个加入群组的消费者将成为“群主”
2.群主从协调器获取群组的成员列表，并负责给每一个消费者分配分区，群主使用实现了PartitionAssignor接口的类来决定哪些分区应该被分配给那个消费者
3.分配完毕后，群主把分配情况列表发送给群组协调器，协调器再把这些信息发送给所有消费者
4.每个消费者只能看到自己的分配信息，只有群主知道群组里所有消费者的分配信息
```

- #### 创建消费者
```
1.在读取消息之前，需要先创建一个KafkaConsumer对象，消费者对象有3个必要的属性：
  * bootstrap.servers：指定了Kafka集群的连接字符串
  * key.serializer和value.serializer：使用指定的类把字节数组转换成java对象
  * group.id：不是必须的属性，指定kafkaConsumer属于哪一个消费者群组，创建一个不属于任何群组的消费者也是可以的
2.创建消费者对象实例
  Properties props = new Properties();
  props.put("bootstrap.servers","broker1:9092,broker2:9092");
  // group.id指定消费者属于那个群组
  props.put("group.id","CountryCounter");
  props.put("key.serializer","org.apache.kafka.common.serialization.StringSerializer");
  props.put("value.serializer","org.apache.kafka.common.serializer.StringSerializer");
  
  KafkaCosumer<String,String> consumer = new KafkaConsumer<String,String>(props);
```

- #### 订阅主题
```
1.使用subscribe()方法接受一个topic列表作为参数，进行主题订阅
  cosumer.subscribe(Collections.singletonList("customerCountries"));
2.在使用subscribe()方法时，可以传入一个正则表达式，可以匹配多个主题，如果有新的主题加入，触发再均衡时，消费者就可以读取新添加的主题
3.订阅所有与test相关的主题，可以使用正则表达式
  consumer.subscribe("test.*");
```

- #### 消息轮询
```
1.消息轮询是消费者API的核心，一旦消费者订阅了主题，轮询就会处理所有的细节，包括群组协调、分区再均衡、发送心跳和获取数据，
  开发者只需要使用简单的API来处理从分区返回的数据
2.消费者代码的主要部分
  try{
    while(true){
      CosumerRecords<String,String> records = consumer.poll(100);
      for(ConsumerRecord<String,String> record : records){
        // dosomething
        // record.topic(),record.partition(),record.offset(),record.key(),record.value()
      }
    }   
  } finally {
      consumer.close();
  }
  * 消费者实际上是一个长期运行的应用程序，通过持续轮询向Kafka请求数据
  * 消费者必须持续对Kafka进行轮询，否则会被认为已经死亡，它的分区会被移交给群组里的其他消费者
  * 传给poll()方法的参数是一个超时时间，用于控制poll()方法的阻塞时间(在消费者的缓冲区没有可用数据时阻塞)，
    如果参数设置为0，poll()方法会立即返回，否则会在指定的毫秒数内一直等待broker返回数据
  * poll()方法返回一个记录列表，每条记录都包含了记录所属主题的信息、分区的信息、记录在分区的偏移量以及记录的键值对
  * 在退出应用程序之前使用close()方法关闭消费者，网络连接和scoket也会随之关闭，并立即触发一次再均衡，
    而不是等待群组协调器发现不在发送心跳并认定它已死亡，这需要更长的时间，导致整个群组在一段时间无法读取消息
3.轮询不只是获取数据，在第一次调用新消费者的poll()方法时，它会负责查找GroupCoordinator，然后加入群组，接受分配的分区
4.心跳也是在轮询中发送出去的，如果发生了再均衡，整个过程也是在轮询期间进行的，所以，要确保在轮询期间任何处理工作都应该尽快完成
```

- #### 消费者配置
```
1.fetch.min.bytes
  * 该属性指定了消费者从服务器获取记录的最小字节数
  * broker在收到消费者的数据请求时，如果可用的数据量小于fetch.min.bytes指定的大小，那么它会等到足够的可用数据时才会返回给消费者
  * 如果没有很多可用的数据，但消费者的CPU使用率却很高，就需要把该属性设置的比默认值大，
    如果消费者的数据比较多，该属性的值设置的大一点可以降低broker的工作负载
2.fetch.max.wait.ms
  * 用于指定broker的等待时间，默认500ms
  * 如果没有足够的消息流入Kafka，消费者获取最小数据量的要求得不到满足，最终导致500ms的延迟
  * 如果fetch.max.wait.ms被设置为100ms，并且fetch.min.bytes被设置为1MB，Kafka在收到消费者请求时，要么返回1MB数据，要么返回可用数据，看那个条件先满足
3.max.partition.fetch.bytes
  * 该属性指定了服务器从每个分区返回给消费者的最大字节数，默认值是1MB
  * kafkaConsumer.poll()方法从每个分区返回的记录最多不超过max.partition.fetch.max指定的字节
  * max.partition.fetch.size的值必须比broker能够接收的最大消息的字节数(max.message.size属性)大，否则消费者可能无法读取这些消息，导致消费者一致挂起重试
  * 消费者需要频繁的调用poll()方法来避免会话过期和发生分区在均衡，如果单次调用poll()返回的数据太多，消费者需要更多的时间来处理数据，
    可能无法及时进行下一个轮询来避免会话过期，可以把max.partition.fetch.bytes的值改小，或延长会话过期时间
4.session.timeout.ms
  * 该属性指定了消费者在被认为死亡之前可以与服务器断开连接的时间，，默认是3s
  * 如果消费者没有在seesion.timeout.ms指定的时间内发送心跳给群组协调器，就被认为已经死亡，协调器就会触发在均衡，把分区分配给群组里的其他消费者
5.heart.interval.ms
  * 该参数指定了在poll()方法向协调器发送心跳的频率
  * session.timeout.ms指定了消费者可以多久不发送心跳，heartbeat.interval.ms必须比session.timeout.ms小，一般是session.timeout.ms的三分之一
  * session.timeout.ms值设置的比默认小，可以更快的检测和恢复奔溃节点，不过长时间的轮询或垃圾收集可能导致非预期的再均衡，
    把属性的值设置的大些，可以减少意外的再均衡，不过检测节点奔溃需要更长的时间
6.auto.offset.reset
  * 该属性指定了消费者在读取一个没有偏移量的分区或偏移量无效的情况下该如何处理
  * 默认值latest：在偏移量无效的情况下，消费者从最新的记录开始读取数据
  * 其他值earliest：在偏移量无效的情况下，消费者从起始位置读取分区的记录
7.enable.auto.commit
  * 该属性指定了消费者是否自动提交偏移量，默认值为true
  * 为了尽量避免出现重复数据和数据丢失，可以设置为false，由自己控制何时提交偏移量
  * 如果设置为true，还可以通过设置auto.commit.interval.ms属性来控制提交的频率
8.partition.assignment.strategy
  * 该参数指定Kafka的分配策略
  * PartitionAssignor根据给定的消费者和主题，决定哪些分区应该被分配到那个消费者
  * Kafka有两个默认的分配策略
    - Range策略：把主题的若干个连续的分区分配给消费者
      使用Range策略，并且分区数量无法被消费者数量整除，最后的消费者分配的分区总是比之前的消费者分配的分区数要少
    - RoundRobin策略：把主题的所有分区逐个分配给消费者
      如果所有消费者都订阅了相同的主题，RoundRobin策略会给所有的消费者分配相同数量的分区（或最多就差一个分区）
  * 可以通过设置partition.assignment.strategy来选择分区策略，默认使用RangeAssignor，这个类实现了Range策略      
9.client.id
  * 该属性可以是任意字符串，broker用来标示从客户端发送来的消息，通常被用在日志、度量指标和配额里
10.max.poll.records
  * 该属性用于控制单次调用call()方法能够返回的记录数量，可以控制在轮询中需要处理的数据量
11.receive.buffer.bytes和send.buffer.bytes
  * 用来设置scoket在读写数据时用到TCP缓冲的区大小
  * 如果设置为-1，就使用操作系统默认的大小
```

- #### 提交和偏移量
```
1.每次调用poll()方法，它总返回由生产者写入Kafka但还没有被消费者读取过的记录，因此可以追踪到哪些记录是被群组里的那个消费者读取的
2.Kafka不会像其他JMS队列需要得到消费者的确认，消费者可以使用Kafka来追踪消息在分区中的位置(偏移量)
3.更新分区当前位置的操作就是提交
4.消费者会往_consumer_offset的特殊主题发送消息，消息里包含了每个分区的偏移量
5.如果消费者一直处于运行状态，偏移量就没什么用处，如果发生了再均衡，每个消费者就需要读取每个分区最后一次提交的偏移量，然后从偏移量指定的位置继续处理
6.如果消费者提交的偏移量小于客户端处理的最后一个消息的偏移量，那么处于两个偏移量之间的消息就会被重复处理
7.如果提交的偏移量大于客户端处理的最后一个消息的偏移量，那么处于两个偏移量之间的消息就会丢失
```

- #### 自动提交
```
1.最简单的提交方式是让消费者自动提交偏移量
  * 如果enable.auto.commit被设置为true，那么每过5s，消费者会自动把poll()方法接收到的最大偏移量提交上去
  * 提交时间间隔由auto.commit.interval.ms控制，默认值是5s
2.自动提交也是在轮询中进行的，消费者每次轮询时都会检查是否该提交偏移量，如果是，就会提交从上一次轮询返回的偏移量
3.如果在最后一次提交后发生了再均衡，再均衡之后，消费者从最后一次提交的偏移量位置开始读取消息，最后一次提交后的消息就会被重复消费
4.可以通过修改提交时间间隔来更频繁的提交偏移量，减小可能出现重复消息的时间窗，不过这种情况也是无法避免的
5.自动提交虽然方便，但没有方法来避免重复处理消息的情况
```

- #### 提交当前偏移量
```
1.可以通过控制偏移量提交时间来消除丢失消息的可能性，并在发生再均衡时减少重复消费的数量
2.消费者API提供了另一种提交偏移量的方式，开发者可以在必要时提交当前偏移量，而不是基于时间间隔
3.把auto.commit.offset设置为false，让应用程序决定何时提交偏移量，使用commitSync()方法提交偏移量最简单可靠，
  这个API会提交poll()方法返回的最新偏移量，提交成功后马上返回，如果提交失败就抛出异常
4.commitSync()方法会提交由poll()返回的最新偏移量，如果发生了再均衡，从最近一批消息到发生在均衡之间的所有消息都将被重复处理
5.处理最近一批消息后使用commitSync()方法提交偏移量的实例
  while(true){
    ConsumerRecord<String,String> records = consumer.poll();
    for(ConsumerRecord<String,String> record : records){
        // dosomething
    }
    try{
        consumer.CommitSync();
    } catch(Exception e){
        // commit failed
    }
  }
  * 处理完当前批次的消息，在轮询更多消息之前，调用commitSync()方法提交当前批次最新的偏移量
  * 只要没有发生不可恢复的错误，commitSync()方法会一直尝试直至提交成功，如果提交失败，只能把异常记录到错误日志里
```

- #### 异步提交
```
1.手动提交在broker对提交请求作出响应之前，应用程序会一直阻塞，这样会限制应用程序的吞吐量，可以降低提交频率来提升吞吐量，
  但如果发生了再均衡，会增加重复消息的数量
2.异步提交的消费者API，在发送提交请求后，无需等待broker的响应
  while(true){
    ConsumerRecord<String,String> records = consumer.poll(100);
    for(ConsumerRecord<String,String> record : records){
        // dosomething
    }
    // 异步提交
    consumer.commitAsync();
  }
  * 在成功提交或碰到无法恢复的错误之前，commitSync()会一直重试，但commitAsync()不会，这是因为在它收到服务器响应时，可能有一个更大的偏移量已经提交
3.commitAsync()也支持回调，在broker做出响应时会执行回调，回调经常被用于记录提交错误或生成度量指标，在进行重试时，一定要注意提交顺序
  while(true){
    ConsumerRecords<String,String> records = consumers.poll(100);
    for(ConsumerRecord<String,String> record : records){
        // dosomething
    }
    cosumer.commitAsync(new OffsetCommitCallback(){
      public void onComplete(Map<TopicPartition,OffsetAndMetaData> offsets,Exception e){
      if(e != null){
          // commit failed
      }
    });
  }
4.重试异步提交
  * 可以使用一个单调递增的序号来维护异步提交的顺序
  * 在每次提交偏移量或在回调里提交偏移量时递增序号，在重试前，先检查回调的序号和即将提交的偏移量是否相等，如果相等，说明没有新的提交，
    就可以安全的进行重试，如果序列号比较大，说明一个新的提交已经发送出去了，应该停止重试
```

- #### 同步和异步组合提交
```
1.一般情况，对偶尔出现的提交失败，不进行重试也不会有太大的问题，因为后续的提交总会成功，如果是发生在消费者关闭或在均衡的最后一次提交，就要确保能够提交成功
2.在消费者关闭前一般组合使用commitAsync()和commitSync()
  try{
      while(true){
        ConsumerRecords<String,String> records = consumer.poll(100);
        for(ConsumerRecord<String,String> record : records){
            // dosomething
        }
        consumer.commitAsync();
      }
  } finally{
    try{
       consumer.commitSync();    
    } finally{
       consumer.close();    
    }  
  }
  * 如果直接关闭消费者，就没有下一次提交发生了，使用commitSync()方法会一直重试，直到提交成功或发生无法恢复的错误  
```

- #### 提交特定的偏移量
```
1.提交偏移量的频率与处理消息批次的频率是一样的，commitAsync()和commitSync()都只会提交批次的最后一个偏移量
2.消费者API允许在调用commitAsync()和commitSync()方法时，传进去希望提交的分区和偏移量的map，
  因为消费者可能不只读取一个分区，需要跟踪所有分区的偏移量，在这个层面控制偏移量的提交会让代码变的复杂
3.提交特定偏移量的实例：
  // 用于跟踪偏移量的map
  private Map<TopicPartition,OffsetAndMetadata> currentOffsets = new HashMap<>();
  int count =0;
  ...
  while(true){
      ConsumerRecords<String,String> records = consumer.poll(100);
      for(ConsumerRecord<String,String> record : records){
         // dosomething
         
         // 使用期望处理的下一个消息的偏移量更新map里的偏移量
         currentOffsets.put(new TopicPartition(record.topic(),record.partition()),new OffsetAndMetadata(record.offset()+1,"no metadata"));
         // 没处理1000条消息提交一次偏移量
         if(count % 1000 == 0){
            // 使用同步提交
            consumer.commitAsync(currentOffsets,null); 
         }
         count++;
      }
  }
```

- #### 再均衡监听器
```
1.如果消费者准备了一个缓冲区用来处理偶发的事件，那么在失去分区所有权之前，需要处理在缓存区中积累下的记录
2.在消费者失去对一个分区的所有权之前，需要提交最后一个已经处理记录的偏移量，可能还需要关闭文件句柄、数据库连接等
3.在为消费者分配新分区或移除旧分区时，可以通过消费者API执行一些应用程序代码，在调用subscribe()方法时传入一个ConsumerRebalanceListener实例就可以了
  * public void onPartitionsRevoked(Collection<TopicPatition> partitions)方法：
    会在再均衡开始之前和消费者停止读取消息之后被调用，如果在这时候提交偏移量，下一个接管分区的消费者就知道从哪里开始读取了
  * public void onPartitionsAssigned(Collection<TopicPartitions>)方法：
    会在重新分配分区之后和消费者开始读取消息之前被调用
4.在消费者失去分区所有权之前通过onPartitionsRevoked()方法提交偏移量
  private Map<TopicPartition,OffsetAndMetadata> currentOffsets = new HashMap<>();
  // 实现ConsumerRebalanceListener接口
  private class HandleRebalance implements ConsumerRebalanceListener {
    public void onPartitionsAssigned(Collection<TopicPartition> partitions){
      // 获取分区所有权，开始读取消息，不需要其他处理   
    }
    public void onPartitionsRevoked(Collection<TopicPartition> partitions){
        // 确保再分区之前提交偏移量
        consumer.commitSync(currentOffsets);
    }
  }
  try {
    // 将ConsumerRebalanceListener对象传给subscribe()方法
    consumer.subscribe(topics,new HandleRebalance());  
    // 轮询消息
    while(true){
        CosnumerRecords<String,String> records = consumer.poll(100);
        for(ConsumerRecord<String,String> record : records){
            // dosomething
            currentOffsets.put(new TopicPartition(record.topic(),record.partition()),new OffsetAndMetadata(record.offset()+1,"no metadata"));
        }
        consumer.commitAsync(currentOffsets,null);
    }
  } finally {
    try {
      consumer.Sync(currentOffsets);    
    } finally {
        consumer.close();
    } 
  }
  * 如果发生再均衡，要在即将失去分区所有权时提交偏移量
  * 提交的是最近处理过的偏移量，而不是批次中还在处理的最后一个偏移量
  * 要提交所有分区的偏移量，而不是即将失去所有权的分区的偏移量
```

- #### 退出轮询
```
1.如果确定退出消息轮询，需要在另一个线程中调用consumer.wakeup()
2.consumer.wakeup()是消费者唯一一个可以从其他线程中安全调用的方法
3.调用consumer.wakeup()可以退出poll()，并抛出WakeupException异常，或者如果调用consumer.wakeup()时线程没有等待轮询，那异常将在下一轮poll()时抛出
4.一般不需要处理WakeupException，因为它只是用于跳出循环的一种方式
5.在退出线程前调用consumer.close()是很有必要的，它会提交任何还没有提交的东西，并向群组协调器发送消息，告知自己已离开群组，
  接下来就会触发再均衡，而不需要等待会话超时
6.退出轮询的实例
  try{
    while(true){
       ConsumerRecords<String,String> records = consumer.poll(100); 
       for(ConsumerRecord<String,String> record : records){
        // dosomething
       }
       consumer.commitAsync();
    }
  } catch(WakupException e){
    // 在另一个线程中调用wakeup()方法，导致poll()抛出WakeupException，不用处理该异常  
  } finally {
    // 退出之前，确保彻底关闭消费者
    consumer.close();
  }
```

- #### 反序列化器
```
1.生产者需要用序列化器把对象转换成字节数组在发送给Kafka，类似的，消费者需要用反序列化器把Kafka接收到的字节数组转换成Java对象
2.使用Avro和schema注册表进行序列化和反序列化的优势在于：
  * AvroSerializer可以保证写入主题的数据与主题的schema是兼容的，即可以使用相同的反序列化器和schema来反序列化数据
  * 在生产者或消费者里出现的任何一个与兼容性有关的错误都会被捕捉到，且带有消息的描述
3.建议使用标准的消息格式，如JSON、Thrift或Avro，使用Avro反序列化的实例：
  Properties props = new Properties();
  props.put("bootstrap.servers","broker1:9092,broker2:9092");
  props.put("group.id":"CountryCounter");
  props.put("key.serializer","org.apache.kafka.common.serialization.StringDeserializer");
  // 使用KafkaAvroDeserializer来反序列化Avro消息
  props.put("value.serializer","io.confluent.kafka.serializer.KafkaAvroDeserializer");
  // 指向schema的存放位置，消费者可以使用由生产者注册的schema来反序列化消息 
  props.put("schema.registry.url",schemaUrl);
  String topic = "customerContacts";
  
  KafkaConsumer consumer = new KafkaConsumer(createConsumerConfig(brokers,groupId,url));
  
  // 订阅主题 
  consumer.subcribe(Collections.singletonList(topic));
  
  while(true){
    // 将类Customer做为消息值的类型
    ConsumerRecords<String,Customer> records = consumer.poll(1000);
    for(ConsumerRecord<String,Customer> record : records){
       // dosomething
       // record.value()返回Customer类的实例
    }
    consumer.commitAsync(); 
  }
```