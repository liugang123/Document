- #### 初识Kafka
```
1.Kafka最初是LinkedIn的一个内部基础设施系统，是为了解决LinkedIn数据管道问题应用而生的，
  它的设计目的是想提供一个高性能的消息系统，可以处理多种数据类型，并能够实时提供纯净且结构化的用户活动数据和系统度量指标
2.Kafka是一个流平台，在这个流平台上可以发布和订阅数据流，并把它们保存起来、进行处理，这就是构建Kafka的初衷
3.Kafka有点像消息系统，允许发布和订阅消息流，类似于消息中间件RabbitMQ、ActiveMQ
4.Kafka作为一个分布式系统，以集群的方式运行，可以自由伸缩，处理所有应用程序的数据流
  Kafka按照设置存储数据，保存多久都可以，作为数据连接层，Kafka提供了数据传递保证--可复制、持久化
5.消息中间件只会传递消息，而Kafka的流式数据处理能力只用很少的代码就能够动态的处理派生流和数据集，而不仅仅是“另一个消息队列”
6.从另一个角度看，Kafka可以看作实时版的Hadoop，Hadoop可以存储和定期处理大量的数据文件，而Kafka可以存储和持续处理大型的数据流，
  两者之间的最大不同体现在持续的低延迟处理和批处理之间的差异上，
  Haddop和大数据主要应用在数据分析上，而Kafka因其底延迟的特点更适合用在核心的业务应用上
7.Kafka一般被称为“分布式提交日志”或“分布式流平台”，文件系统或数据库提交日志用来提供所有事务的持久记录，通过重放这些日志可以重建系统的状态
8.Kafka的数据是按照一定顺序持久化保存的，可以按需读取，kafka的数据分布在整个系统中，具备数据故障保护和性能伸缩能力
```

- #### 数据的流动
```
1.数据为企业的发展提供动力，从数据中获取信息，并进行分析处理，然后生成更多的数据
2.每个应用程序都会生产数据，包括日志消息、度量指标、用户活动记录、响应时间等
3.把数据从源头移动到可以对它分析处理的地方，然后把得到的结果应用在实际场景中，这样就能确切的知道这些数据告诉我们需要做什么
 如在购物网站上浏览感兴趣的商品，浏览信息就被转化为商品推荐，稍后展示给客户端
4.数据的移动处理完成的越快，系统的反应就越敏捷，花费越少的精力在数据移动上，就越能专注于核心业务 
```

- #### 消息和批次
```
1.Kafka的数据单元被称为消息，消息由字节数组组成，消息里的数据没有特别的格式和含义
2.消息有一个可选的元数据--键，键也是一个字节数组，与消息一样，对于kafka来说没有特殊的含义
3.当消息以一种可控的方式写入不同的分区时，会用到键，为每个键生成一个一致性散列值，然后使用散列值对主题分区数进行取模，
  为消息选择分区，这样可以保证相同键的消息总是被写到相同的分区上
4.为了提高效率，消息被分批次写入Kafka，批次就是一组消息，这些消息属于同一个分区和主题
5.如果每条消息都单独穿行于网络，会导致大量的网络开销，把消息分成批次传输可以减少网络开销，
  这要在时间延迟和吞吐量之间作出权衡：批次越大，单位时间内处理的消息越多，单个消息的传输时间就越长，
  批次数据会被压缩，这样可以提升数据的传输和存储能力，但要做更多的计算处理
```

- #### 消息格式(模式)
```
1.对Kafka来说，字节数组的消息比较晦涩难懂，根据应用程序的需求，消息模式有许多可用的选项，如JSON和XML不仅易用，而且可读性好，
  只是缺乏强类型的处理能力，不同版本之间的兼容性也不是很好
2.Kafka通常采用Apache Avro，它起初是为Hadoop开发的一款序列化框架
  Avro提供了一种紧凑的序列化格式，模式和消息体是分开的，当模式发生变化时，不需要重新生成代码
3.Avro还支持强类型和模式进化，其版本即向前兼容，也向后兼容
4.数据格式的一致性对于Kafka来说很重要，它消除了消息读写操作之间的耦合性，如果读写操作紧密的耦合在一起，
  消息订阅需要升级应用程序才能同时处理新旧两种数据格式，在消息订阅者升级之后，消息发布者才能跟着升级，以便使用新的数据格式
5.定义良好的模式，并把它存放在公共仓库，可以方便理解Kafka的消息结构  
```

- #### 主题和分区
```
1.Kafka的消息通过主题进行分类，主题好比数据库的表，或者文件系统里的文件夹
2.主题被分为若干个分区，一个分区就是一个提交日志，消息以追加的方式写入分区，然后以先入先出的顺序读取
3.由于一个主题一般包含几个分区，因此无法在整个主题范围内保证消息的顺序，但可以保证消息在单个分区内的顺序
4.Kafka通过分区来实现数据冗余和伸缩性，分区可以分布在不同的服务器上，一个主题可以横跨多个服务器，
  以此来提供比单个服务器更强大的性能
5.通常把一个主题的数据看成一个流，不管它有多少分区，流是一组从生产者移动到消费者的数据
6.可以将流式处理与离线处理进行比较，比如Hadoop就是被设计用来在稍后某个时刻处理大量的数据
```

- #### 生产者
```
1.kafka的客户端就是Kafka系统的用户，分为两种基本类型：生产者和消费者
2.生产者创建消息，一般情况，一个消息会被发布到一个特定的主题上
3.生成者默认把消息均匀的分布到主题的所有分区上，而不关心特定消息会被写到那个分区
4.通过消息键和分区器可以把消息直接写到指定的分区，分区器为键生成一个散列值，并将其映射到指定的分区，这样就可保证包含同一个键的消息会被写到同一个分区上
5.生产者可以使用自定义的分区器，根据不同的业务规则将消息映射到分区
```

- #### 消费者
```
1.消费者读取消息，消费者订阅一个或多个主题，并按照消息生成的顺序读取它们
2.消费者通过检查消息的偏移量来区分已经读取过的消息，偏移量是一个不断递增的整数值，在创建消息时，Kafka会把它添加到消息中
3.在给定的分区里，每个消息的偏移量都是唯一的
4.消费者把每个分区最后读取的消息偏移量保存在Zookeeper或Kafka上，如果消费者关闭或重启，它的读取状态不会丢失
5.消费者是消费者群组的一部分，会有一个或多个消费者共同读取一个主题，群组保证每个分区只能被一个消费者使用
6.消费者与分区之间的映射通常被称为消费者对分区的所有权关系
7.如果组群中的一个消费者失效，组群里的其他消费者可以接管失效消费者的工作
```

- #### broker和集群
```
1.一个独立的Kafka服务器被称为broker，broker接收来自生产者的消息，为消息设置偏移量，并提交消息到磁盘保存
2.broker为消费者提供服务，对读取分区的请求作出响应，返回已经提交到磁盘上的消息
3.根据特定的硬盘及其他特性，单个broker可以轻松处理数千个分区以及美妙百万级的消息量
4.broker是集群的组成部分，每个集群都有一个broker同时充当了集群控制器的角色，集群控制器从集群中活跃的成员中选举出来
5.控制器负责管理工作，包括讲分区分配给broker和监控broker
6.在集群中，一个分区从属于一个broker，该broker被称为分区的首领
7.一个分区可以分配给多个broker，这时会发生分区复制，复制机制为分区提供了消息冗余，如果一个broker失效，其他的broker可以接管领导权
8.在一定的期限内kafka会保留消息，kafka的消息保留策略是：要么保留一段时间，要么保留到消息达到一个规定的字节数，
  主题可以设置自己的保留策略，可以将消息保留到不在使用它们为止
```

- #### 多集群
```
1.随着kafka部署数量的增加，基于以下几点，最好使用多个集群：
  * 数据类型分离
  * 安全需求隔离
  * 多数据中心(灾难恢复)
2.如果使用多个数据中心，就需要它们之间复制消息，不过Kafka的消息复制只能在单个集群中进行，不能在多个集群间进行
3.Kafka提供里MirrorMaker工具，可以用来实现集群间的消息复制
  MirrorMaker的核心组件包含一个生产者和一个消费者，两者之间通过一个队列相连
```

- #### 为什么选择Kafka
```
1.多个生产者
  * Kafka可以无缝的支持多个生产者，不管客户端在使用单个主题还是多个主题
  * Kafka适合用来从多个前端系统收集数据，并以统一的格式对外提供数据
2.多个消费者
  * Kafka也支持多个消费者从一个单独的消息流上读取数据，而且消费者之间互不影响
  * 多个消费者可以组成一个组群，它们共享一个消息流，并保证整个组群对每个给定的消息只处理一次
3.基于磁盘的数据存储
  * Kafka不仅支持多个消费者，还允许消费者非实时的读取消息，消息被提交到磁盘，根据设置的保留规则进行保存
  * 每个主题可以设置单独的保留策略，以便满足不同消费者的需求，各个主题可以保存不同数量的消息
  * 持久化的消息可以保证数据不被丢失，消费者可以被关闭，但消费者会继续保留在kafka里，消费者可以从上次中断的地方继续处理消息
  * 消费者可以在应用程序维护时离线一小段时间，而无需担心消息丢失或堵塞在生产者端
4.伸缩性
  * Kafka一开始就被设计成一个具有灵活伸缩性的系统
  * 一个包含多个broker的集群，即使个别broker失效，集群任然可以继续提供服务
  * 要提高集群的容错能力，需要配置较高的复制系统
5.高性能
  * 通过横向扩展生产者、消费者和broker，Kafka可以轻松处理巨大的消息流
  * 在处理大量数据的同时，Kafka还能保证亚秒级的消息延迟
```

- #### Kafka使用场景
```
1.活动跟踪
  * Kafka最初的使用场景是跟踪用户活动的
  * 网站用户与前端应用程序发生交互，前端应用程序生成用户活动相关的消息，这些消息被发布到一个或多个主题上，由后端程序负责读取
2.传递消息
  * Kafka的另一个基本用途是传递消息
  * 应用程序向用户发送通知就是通过传递消息来实现的，这些应用程序组件可以生成消息，而不需要关心消息的格式，也不关心消息如何被发送
  * 一个公共的应用程序会读取这些消息，对它们进行处理：
    - 格式化消息
    - 将多个消息放在同一个通知里发送
    - 根据用户配置的首选项来发送数据
3.度量指标和日志记录
  * Kafka也可以用于收集应用程序和系统度量指标以及日志
  * 应用程序定期把度量指标发布到Kafka主题上，监控系统或告警系统读取这些消息
4.提交日志
  * Kafka的基本概念来源于提交日志，使用Kafka作为提交日志是件顺理成章的事
  * 可以把数据库的更新发布到kafka上，应用程序通过监控事件流来接收数据库的实时更新
5.流处理
  * kafka提供的流处理功能与Hadoop里的map和reduce有点类似，只不过处理的是实时数据流，而Hadoop则处理更长时间片段的数据
```