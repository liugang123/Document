- #### 可靠性保证机制
```
1.kafka可以保证分区消息的顺序
2.只有当消息被写入分区的所有同步副本时，才会被认为“已提交”，通过acks配置参数，可以设置生产者选择不同类型的确认
3.只要还有一个副本是活跃的，那么已经提交的消息就不会丢失
4.消费者只能读取已经提交的消息
```

- ## broker配置
```
1.broker有3个配置参数会影响Kafka消息存储的可靠性
  与其他配置参数一样，可以作用在broker级别，用于控制所有主题的行为，也可以应用在主题级别，用于控制个别主题的行为
2.在主题级别控制可靠，意味着Kafka集群可以同时拥有可靠的主题和非可靠的主题  
```

- #### 1.复制系数
```
1.主题级别的配置参数是replication.factor，在broker级别可以通过default.replication.factor来配置自动创建的主题
2.如果复制系数为N，那么N-1个broker失效的情况下，任然能够从主题读取数据或向主题写入数据，
  所以，更高的复制系数会带来更高的可用性、可靠性和更少的故障
3.复制系数N需要至少N个broker，而且会有N个数据副本，就会占用N倍的磁盘空间，一般会在可用性和存储硬件之间做出权衡
4.大多数情况下，把复制系数设为3已经足够安全了，也有些银行系统使用5个副本，以防不测
5.为了避免机架级别的故障，建议把broker发布在多个不同的机架上，并使用broker.rack参数来为每个broker配置所有机架的名称
6.如果配置了机架的名称，Kafka会保证分区的副本被分布在多个机架上，从而获取更高的可用性
```

- #### 2.不完全的首领选举
```
1.安全的首领选举：当当前首领不可用时，一个同步副本会被选为新首领，
  如果在选举过程中没有丢失数据，即提交的数据同时存在元与所有副本上，这次首领选举就是完全的
2.存在以下两种场景，在首领不可用时其他副本都是不同步的情况：
  * 分区有3个副本其中两个跟随者副本不可用，如果生产者继续往首领写入数据，并且消息得到确认并被提交(acks为0或1)，
    假设首领不可用了，之前的一个跟随者重新启动，就出现了分区的唯一不同步副本
  * 分区有3个副本，因为网络问题导致两个跟随者副本复制消息滞后，尽管跟随者还在复制消息，但已经不同步了，
    首领作为唯一的同步副本继续接收消息，如果此时首领变为不可以用，另外的两个副本就无法成为同步副本
3.对于以上两种情况，有两种选择处理：
  * 如果不同步的副本不能被提升为新首领，那么分区在旧首领恢复之前是不可用的
  * 如果不同步的副本可以被提升为新首领，那么在这个副本变为不同步之后，写入旧首领的消息会全部丢失，导致数据不一致
4.如果允许不同步的副本成为首领，就要承担丢失数据和出现数据不一致的风险
  如果不允许不同步的副本成为首领，就要接受较低的可用性，必须等待原先的首领恢复到可用状态
5.如果把unclean.leader.election.enable设置为true，就是允许不同步的副本成为首领，即不完全选举，那么将面临丢失消息的风险，
  如果把参数设置为false，就要等待原先的首领重新上线，从而降低了可用性
```
- #### 3.最少同步副本
```
1.在主题级别和broker级别上，这个参数都是min.insync.replicas
2.根据Kafka对可靠性保证的定义，消息只有被写入到所有的同步副本之后才被认为已经提交，如果“所有副本”只包含一个同步副本，
  那么在这个副本变为不可用时，数据就会丢失
3.如果要确保已提交的数据被写入不止一个副本，就需要把最少同步副本数量设置成大一点的值，
  对于包含3个副本的主题，如果min.insync.replicas被设置为2，那么至少要存在两个同步副本才能向分区写入数据
4.如果使用该配置，那么当只剩下一个同步副本时，它就会变为只读模式：
  * broker就会停止接收生产者的请求，尝试发送数据的生产者会收到NotEnoughReplicasException异常
  * 消费者仍然可以继续读取已有的数据
  * 为了从只读模式中恢复，必须让不同步的分区恢复为同步
```


