- #### 安装Zookeeper
```
1.Kafka使用Zookeeper保存集群的元数据信息和消费者信息
2.Kafka发行版自带了Zookeeper，可以直接从脚本启动
3.Zookeeper集群被称为群组，Zookeeper使用的是一致性协议，所以建议每个群组里包含奇数个节点，
  因为只有当群组中的大多数节点处于可用状态，Zookeeper才能处理外部的请求
4.如果有一个包含3个节点的群组，那么它允许一个节点失效，如果群组包含5个节点，那么允许2个节点失效
5.一般，不建议一个群组包含超过7个节点，因为Zookeeper使用了一致性协议，节点过多会降低整个群组的性能
7.群组需要一些公共的配置，列出所有服务器的清单，每个服务器还要在数据目录中创建一个myid文件，用于指明自己的ID
8.群组的公共配置文件：
  tickTime=2000
  dataDir=/var/lib/zookeeper
  clientPort=2181
  initLimit=20
  syncLimit=5
  server.1=zoo1.example.com:2888:3888
  server.2=zoo2.example.com:2888:3888
  server.3=zoo3.example.com:2888:3888
  initLimit：表示用于在从节点与主节点之间建立初始化连接的时间上限
  syncLimit：表示允许从节点与主节点处于不同步状态的时间上限
  tickTime：单位毫秒，initLimit和syncLimit是tickTime的倍数，所以initLimit是20*2000ms
  服务器的地址遵从server.X=hostname:peerPort:leaderPort
  X：服务器的ID，必须是一个整数，不过不一定从0开始，也不要求是连续的
  hostname：服务器的机器名或IP地址
  peerPort：用于节点间通信的TCP端口
  leaderPort：用于首领选举的TCP端口
  clientPort：客户端连接到zookeeper群组的TCP端口
  zookeeper群组节点间的通信需要同时使用3个端口：clientPort、peerPort、leaderPort
```

- #### 安装Kafka Broker
```
1.启动Kakfa自带的Zookeeper服务
  ./zookeeper-server-start.sh ../config/zookeeper.properties
2.启动Kafka Broker服务
  ./kafka-server-start.sh ../config/server.properties
3.创建主题topic
  ./kafka-topic.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test
4.查看主题
  ./kafka-topic.sh --zookeeper localhost:2181 --describe --topic test
5.通过生产者控制台发送消息
  ./kafka-console-producer.sh --broker-list localhost:9092 --topic test
6.通过控制台接受消息
  ./kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test  
```

- #### 单个Broker的默认配置
```
1.broker.id
  * 每个broker都需要有一个标识符，使用broker.id来表示，这个值在整个Kafka集群中必须唯一
  * 默认值为0，也可以被设置成其他任意整数
2.bootstrap-servers
  * 如果使用默认配置来启动Kafka，它会监听9092端口
  * 修改port配置参数可以把它设置成任意可用的端口
3.zookeeper.connect
  * 用于保存broker元数据的Zookeeper地址是通过zookeeper.connect来指定的
  * 该配置参数是使用冒号分割的一组hostname:port/path
    - hostname：是Zookeeper服务器的机器名或IP地址
    - port：是Zookeeper的客户端连接端口
    - /path：是可选的Zookeeper路径，作为Kafka集群的chroot环境，如果不指定，默认使用根路径，
      如果指定的chroot路径不存在，broker在启动时会创建 
4.log.dirs
  * Kafka把所有消息都保存在磁盘上，存放日志片段的目录是通过log.dirs指定的
  * 是一组用逗号分割的本地文件系统路径，如果指定多个路径，broker会根据“最少使用”原则，把同一个分区的日志片段保存到同一个路径下
  * broker会往拥有最少数目分区的路径新增分区，而不是往拥有最小磁盘空间的路径新增分区
5.num.recovery.threads.per.data.dir
  * 对以下3种情况，Kafka会使用可配置的线程池来处理日志片段：
    - 服务器正常启动，用于打开每个分区的日志片段
    - 服务奔溃后重启，用于检查和截短每个分区的日志片段
    - 服务正常关闭，用于关闭日志片段
  * 默认情况下，每个日志目录只使用一个线程，因为这些线程只是在服务器启动和关闭时才会用到，所以完全可以设置大量的线程来达到并行操作的目的
  * 设置的参数数值对应的是log.dirs指定的单个日志目录，如果数值为8，并且log.dirs指定了3个路径，那么总共需要24个线程
6.auto.create.topics.enable
  * 默认情况下，Kafka会在以下情况下自动创建主题：
    - 当一个生产者开始往主题写入消息时
    - 当一个消费者开始从主题读取消息时
    - 当任意一个客户端向主题发送元数据请求时
  * 这些行为都是非预期的，根据Kafka协议，如果一个主题不先被创建，就无法知道它是否已经存在
  * 如果显示创建主题，不管是手动创建还是通过其他配置系统来创建，都可以把auto.create.topics.enable设置为false
```

- #### 主题的默认配置
```
1.Kafka为新创建的主题提供了很多默认配置参数，通过管理工具可以为每个主题单独配置一部分参数，比如分区个数和数据保留策略
2.服务器提供的默认配置可以作为基准，适用于大部分主题
3.num.patitions
  * 指定新创建的主题将包含多少个分区，默认值为1
  * 主题的分区个数可以增加，当不能减少分区的个数
  * 如果要让一个主题的分区个数少于num.partitions指定的值，需要手动创建该主题
  * Kafka集群通过分区对主题进行横向扩展，当有新的broker加入集群时，可以通过分区个数来实现集群的负载均衡 
4.log.retention.ms
  * Kafka通常根据时间来决定数据可以被保留多久，默认使用log.retention.hours参数来配置时间，默认值为168小时，即一周
  * 还有其他两个参数log.retention.minutes和log.retention.ms，3个参数的作用是一样的，都是决定消息多久以后会被删除，推荐使用log.retention.ms
  * 如果指定了不止一个参数，Kafka会优先使用具有最小值的那个参数
  * 根据时间保留数据是通过检查磁盘上日志片段文件的最后修改时间来实现的，最后修改时间就是日志片段的关闭时间，也就是文件里最后一个消息的时间戳
5.log.retention.bytes
  * 通过保留的消息字节数来判断消息是否过期，作用在每一个分区上
  * 如果有一个包含8个分区的主题，并且log.retention.bytes被设置为1G，那这个主题最多可以保留8G的数据
  * 当主题的分区个数增加时，整个主题可以保留的数据也随之增加
  * 如果同时设置了log.retention.bytes和log.retention.ms，只要任意一个条件得到满足，消息就会被删除
6.log.segment.bytes
  * 用来控制日志片段关闭的参数，当日志片段达到log.segment.sytes指定的上限时，当前日志片段就会被关闭，默认值是1G
  * 一个新的日志片段被关闭，就开始等待过期，这个参数的值越小，就会越频繁的关闭和分配新文件，从而降低磁盘写入的整体效率
7.log.segment.ms
  * 另一个控制日志片段关闭时间的参数，指定了多长时间之后日志片段会被关闭
  * 默认情况下，log.segment.ms没有设定值，所以只根据大小来关闭日志片段
  * 使用基于时间的日志片段时，要着重考虑并行关闭多个日志片段对磁盘性能的影响，因为在broker重启之后就开始计算日志片段的过期时间，对于数据量小的分区，
    日志片段的关闭操作总是同时发生
8.message.max.bytes
  * broker通过设置message.max.bytes参数来限制单个消息的大小，默认值为1MB
  * 如果生产者尝试发送的消息超过这个大小，不仅消息不会被接受，还会收到broker返回的错误消息
  * 改参数指定的是压缩后消息的大小，只要压缩后的消息小于message.max.bytes指定的值，消息的实际大小可以远大于这个值
  * 这个值对性能的影响明显，指越大，负责处理网络连接和请求的线程就要花越多的时间处理这些请求，还会增加磁盘写入块的大小，影响IO吞吐量
```

- #### 硬件的选择
```
1.磁盘吞吐量
  * 生产者客户端的性能直接受到服务器端磁盘吞吐量的影响
  * 生产者生成的消息必须被提交到服务器保存，大多数客户端在发送消息之后一直等待，直到至少有一个服务器确认消息已经成功提交为止
  * 磁盘写入速度越快，生成消息的延迟就越低
  * 固态硬盘的查找和访问速度都很快，提高了最好的性能，机械硬盘更便宜，单块硬盘的容量也更大
2.磁盘容量
  * 需要多大的磁盘容量取决于需要保留的消息数量
  * 如果服务器每天会收到1TB消息，并且保留7天，就需要7TB的存储空间，而且还要为其他文件提供至少10%的额外空间
3.内存
  * 磁盘性能影响生产者，而内存影响消费者
  * 消费者一般从分区尾部读取消息，消息者读取的消息会存放在系统的页面缓存中，这比磁盘上重新读取要快的多
4.网络
  * 网络吞吐量决定Kafka能够处理的最大数据流量，它和磁盘存储是制约Kafka扩展规模的主要因素
  * 对于给定的主题，一个生产者可能每秒钟写入1MB数据，但可能同时有多个消费者瓜分网络流量
5.CPU
  * 与磁盘和内存相比，Kafka对计算处理能力的要求相对较低，不过在一定程度上还是会影响整体的性能
  * 服务器对消息进行批量解压，设置偏移量，然后进行批量压缩，在保存到磁盘上，这就是Kafka对计算处理能力所要求的地方
```

- #### Kafka集群
```
1.使用集群最大的好处是可以跨服务器进行负载均衡，在就是可以使用复制功能来避免因单点故障造成的数据丢失
2.一个Kafka集群需要多少个broker取决于以下因素：
  * 需要多少磁盘空间来保留数据，以及单个broker有多少可用空间
  * 集群处理请求的能力
3.要把一个broker加入到集群里，只需要修改两个配置参数：
  * 所有broker都必须配置相同的zookeeper.connect，该参数指定了用于保存元数据的Zookeeper群组和路径
  * 每个broker都必须为broker.id参数设置唯一值
```